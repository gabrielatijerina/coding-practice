{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Yourself \n",
    "- I’m a nearly native Texan -- I grew up just down the road, in Seguin. \n",
    "- I have a **bachelor’s degree from Texas Woman’s University** and I recently graduated from **Codeup’s 22-week data science program**.  \n",
    "- Prior to Codeup, I worked for **10 years as a secondary math teacher** within SCUCISD.\n",
    "- HOBBIES: reading nonfiction, crafting/DIY, working on landscaping with my husband. \n",
    "- Enjoy reading and learning new things\n",
    "- Data science to me is challenging and invigorating - like solving a puzzle every day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Words\n",
    "- learning agility (knowing what to do when you don't know what to do / know where to look how to ask and then apply that experience to the problem)\n",
    "- self efficacy (growth mindset / confidence in my ability to learn/do the task at hand)\n",
    "- good communicator  (written and oral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Experience\n",
    "\n",
    "- Most recently, as a special education case manager, I was required to write IEPs (individual education plans for my 13 students each year).\n",
    "    - meeting with service providers to write goals\n",
    "    - read reports of speech therapists and counselors, etc. \n",
    "    - read testing data and summarize\n",
    "    - analyzing psychological testing summaries\n",
    "    \n",
    "- Served as Managing Editor of the Christian Beacon in San Antonio from 2001 to 2005. \n",
    "    - Informational writing/feature writing. \n",
    "\n",
    "- First job out of college was a litigation paralegal.\n",
    "    - deposition summaries\n",
    "    - employment & medical record summaries\n",
    "    - summaries of reports from technical experts (biomechanical engineers, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>     \n",
    "\n",
    "# MODEL: Decision Tree \n",
    "<font color = 'black'>The **goal** of a Decision Tree model is to **split the data into homogeneous groups containing only one class \n",
    "in each group**. \n",
    "- <font color = 'black'>The model **begins by asking a question**, such as 'was the victim armed?'\n",
    "- <font color = 'black'>If true, it takes the left path, grouping that instance with others that were also armed. \n",
    "    And a second question (like, did the victim have a firearm?) is applied to further split the group.\n",
    "- <font color = 'black'>Otherwise, the observation is grouped to the right and another question (was the victim fleeing?) is applied to further divide that data.\n",
    "- <font color = 'black'>This process **continues iteratively until it reaches a maximum preset depth**.   \n",
    "- <font color = 'black'>At that point, a prediction is generated to classify groups based on the target class that has the most instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUNING A DECISION TREE\n",
    "\n",
    "- adjusting a decision tree to **minimize misclassification error**\n",
    "- Pruning reduces the size of decision trees by removing parts of the tree that do not provide power to classify instances. - Of the ML algorithms **decision trees are most prone to overfitting. Pruning reduces risk of overfit. **\n",
    "- PRE-PRUNING - actually **limiting the depth** before the tree is built.\n",
    "- PRUNING - removing **non-critical/redundant sections** (for classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>\n",
    "\n",
    "# MODEL: Random Forest\n",
    "\n",
    "<font color = 'black'>The Random Forest Classifier algorithm bases its estimate on the **aggregated/averaged** results of multiple (usually between 10 - 128) decision tree models. \n",
    "- Basically, it’s relying on the “wisdom of the crowd” to form an aggregate prediction.\n",
    "- Under the hood, the algorithm is building multiple decision trees and is adding randomness to the model by considering a random set of features for each tree.  \n",
    "- With Scikit-learn, the Random Forest algorithm has a tool that **scores each feature’s relative importance** on its prediction. \n",
    "- Random Forest can be used for both classification and regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>\n",
    "\n",
    "# MODEL: Naive Bayes\n",
    "\n",
    "<font color = 'black'>Implies **absolute independence of features** — a condition probably never met in real life.\n",
    "- <font color = 'black'>It predicts membership probabilities for each class such as the **probability that given record or data point belongs to a particular class.** The class with the highest probability is considered as the most likely class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>    \n",
    "\n",
    "# MODEL: Logistic Regression\n",
    "\n",
    "<font color = 'black'>Logistic regression is a statistical method for predicting binary classes. \n",
    "- <font color = 'black'>similar to linear regression -- but rather than continuous target (like house price), you have a discrete target (churn/no churn) \n",
    "- <font color = 'black'>Linear regression is estimated using Ordinary Least Squares (OLS) while logistic regression is estimated using **Maximum Likelihood Estimation** (MLE) approach.\n",
    "- <font color = 'black'>The dependent variable in logistic regression follows Bernoulli Distribution.\n",
    "Estimation is done through maximum likelihood.\n",
    "<font color = 'black'>No R Square, Model fitness is calculated through Concordance, KS-Statistics.\n",
    "\n",
    "- <font color = 'black'>can be **binary**, where target variable has only two possible outcomes (spam/not spam, cancer/no cancer) \n",
    "- <font color = 'black'>can be **multinomial**: target variable has three or more nominal categories (predicting the type of wine) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'green'>    \n",
    "\n",
    "# MODEL: K-Nearest Neighbor\n",
    "\n",
    "<font color = 'black'>\n",
    "\n",
    "    \n",
    "- distance-based supervised machine learning algorithm\n",
    "- assumes that similar things exist in close proximity. In other words, similar things are near to each other.\n",
    "- KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'maroon'>\n",
    "\n",
    "# OVERFITTING\n",
    "    \n",
    "- Overfitting happens when a **model memorizes its training data so well that it is learning noise on top of the signal**\n",
    "- Underfitting is the opposite: the model is too simple to find the patterns in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'maroon'>\n",
    "\n",
    "# STATS: Confusion Matrix\n",
    "\n",
    "<font color ='black'>  A confustion matrix\n",
    "\n",
    "<img src=\"confusion_matrix2.png\" width=\"400\">\n",
    "<img src=\"ConMat.png\" width=\"400\">\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATS: Evaluation Metrics\n",
    "\n",
    "This is a list of rates that are often computed from a confusion matrix for a binary classifier:\n",
    "\n",
    "<font color = 'red'>**Accuracy**<font color = 'black'>: Overall, how often is your classifier correct? The accuracy returns the proportion of correct predictions. <br>\n",
    "- Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    " \n",
    "<font color = 'red'>**Precision**<font color = 'black'>: When it predicts yes, how often is it correct? The precision returns the proportion of true positives among all the values predicted as positive.<br>\n",
    "- Precision = TP/(TP + FP) \n",
    " \n",
    "<font color = 'red'>**Recall**<font color = 'black'>: The recall returns the proportion of positive values correctly predicted. (sensitity)\n",
    "- Recall = TP/(TP + FN) \n",
    " \n",
    "<font color = 'red'>**Specificity**<font color = 'black'>: The specificity returns the proportion of negative values correctly predicted.\n",
    "- Specificity: TN/(TN + FP) \n",
    " \n",
    "<font color = 'red'>**F1-score**<font color = 'black'>: The f1-score is the harmonic mean of precision and recall. It is often used to compare classifiers.\n",
    "- F1-score = (2 x Precision x Recall)/(Precision + Recall) \n",
    "- The harmonic mean gives more weight to the lower value, so a high F1-score means that both precision and recall are high.\n",
    "\n",
    "<font color = 'red'>**Misclassification Rate**<font color = 'black'>: Overall, how often is it wrong?\n",
    "- (FP+FN)/total = (10+5)/165 = 0.09 equivalent to 1 minus Accuracy (aka \"Error Rate\")\n",
    "    \n",
    "<font color = 'red'>**True Positive Rate**<font color = 'black'>: When it's actually yes, how often does it predict yes?\n",
    "TP/actual yes = 100/105 = 0.95 aka \"Sensitivity\" or \"Recall\"\n",
    "    \n",
    "<font color = 'red'>**False Positive Rate**<font color = 'black'>:  TYPE 1 When it's actually no, how often does it predict yes?\n",
    "FP/actual no = 10/60 = 0.17\n",
    "    \n",
    "<font color = 'red'>**True Negative Rate**<font color = 'black'>: When it's actually no, how often does it predict no?\n",
    "TN/actual no = 50/60 = 0.83 equivalent to 1 minus False Positive Rate (aka \"Specificity\")\n",
    "    \n",
    "   \n",
    "<font color = 'red'>**Prevalence**<font color = 'black'>: How often does the yes condition actually occur in our sample?\n",
    "actual yes/total = 105/165 = 0.64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATS: p-value\n",
    "\n",
    "-The P value, or calculated probability, is the probability of finding the observed (or more extreme) results when the null hypothesis (H0) of a study question is true – the definition of ‘extreme’ depends on how the hypothesis is being tested. \n",
    "- P is also described in terms of rejecting H0 when it is actually true, however, it is not a direct probability of this state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATS:  ROC Curve & AUC\n",
    "\n",
    "- **Receiver Operating Characteristic** (ROC) curve is the plot of true positive rate against the false positive rate. It shows the tradeoff between sensitivity and specificity and is used to measure the performance of **binary classifiers**\n",
    "\n",
    "- **Area Under the Curve**\n",
    "\n",
    "<div>\n",
    "<img src=\"roc.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "- Higher the AUC value, higher the performance of the model  \n",
    "- Any model with ROC curve above random guessing classifier line can be considered as a better model.\n",
    "- Any model with ROC curve below random guessing classifier line can outrightly be rejected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>\n",
    "    <br>\n",
    "\n",
    "# PROJECT: Capstone\n",
    "\n",
    "</font>America's Blues: an Analysis of Fatal Police Encounters\n",
    "\n",
    "Our capstone team worked with a data set of over 14,000 police-officer involved fatalities from a dataset from FatalEncounters.org.\n",
    "- sought to identify top drivers of civilian fatalities to shed light on how to save more lives\n",
    "- used Pandas, Seaborn, Matplotlib and Tableau to clean, prep and explore our data\n",
    "- used Scikit learn we built and applied classification models to predict the threat level of the victim (attacker/non-attacker)\n",
    "- our final predictive model was a decision tree model whose accuracy on out-of-sample data represented a 39% improvement over baseline\n",
    "- based on the top features associated with attackers, we were able to provide recommendations to help save lives\n",
    "- attackers -- armed, fleeing, race, age\n",
    "- models tried: decision tree, k-nearest neighbor, random forest, logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our Decision Tree model is to split the data into three homogeneous groups containing only one threat level \n",
    "in each group. \n",
    "\n",
    "Here's a simplified example  of how our classification model works:  \n",
    "\n",
    "The# <font color = 'green'> MODEL: Decision Tree model begins by asking a question, such as 'was the victim armed?  '\n",
    "\n",
    "If true, it takes the left path, grouping that instance with others that were also armed.  And a second question (like, did the victim have a firearm?) is applied to further split the group.\n",
    "\n",
    " Otherwise, the observation is grouped to the right and another question  (was the victim fleeing?)  is applied to further divide that data.\n",
    "\n",
    "\n",
    "\n",
    "This process continues iteratively until it reaches a maximum preset depth.   (Our model had a maximum depth of three.)  \n",
    "\n",
    "At that point, a prediction is generated to classify groups based on the target class that has the most instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>\n",
    "    <br>\n",
    "\n",
    "# PROJECT: NLP/Classification - Predicting Primary Coding Languages\n",
    "</font>\n",
    "- used Pandas, Matplotlib, BeautifulSoup and NLtool kit to acquire, prepare and explore the contents of read me files scraped from GitHub repositories referencing cybersecurity\n",
    "- normalized and vectorized the text\n",
    "- used a KNN Model to predict the coding language of the repository\n",
    "- Using a KNN Model, I was able to predict language with an accuracy of 49% (compared to a baseline of 42%)\n",
    "- Python, Jupyter, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>\n",
    "    <br>\n",
    "\n",
    "# PROJECT: Regression - Predicting Home Values\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>\n",
    "    <br>\n",
    "\n",
    "# PROJECT: CLUSTERING - Predicting Log Error\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'>\n",
    "    \n",
    "\n",
    "# PROJECT: CLASSIFICATION - Lifestyle Predictors of High Personal Achievement\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>\n",
    "    <br>\n",
    "\n",
    "# My Questions\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- start date?\n",
    "- remain 100% remote?\n",
    "- opportunity to transition to FTE with USAA?\n",
    "- **what tools** are used in this position? (ex. Jupyter notebook, SQL, GitHub, MS Word, Trello/Agile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
